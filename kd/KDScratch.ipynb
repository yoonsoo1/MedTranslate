{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A8C8tfJVjgr"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install sentence_transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "%cd \"./drive/My Drive\""
      ],
      "metadata": {
        "id": "W-s1U8p7Vr1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "TE4EVr3yVtbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data (temporary)"
      ],
      "metadata": {
        "id": "cSYDWFv4WcFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./processed_train_data.csv\")\n",
        "X = df[\"Expert\"].values\n",
        "# y = Load in labels here\n",
        "\n",
        "# Or use/create DataLoaders"
      ],
      "metadata": {
        "id": "neFufKcRV4e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions (temporary)"
      ],
      "metadata": {
        "id": "S7Dyy8YlWfUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_logits(model, X, tokenizer):\n",
        "  # Tokenize the input text\n",
        "  inputs = tokenizer.encode(\"$simple$ ; $expert$ = \" + X, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(inputs, decoder_input_ids=inputs).logits\n",
        "\n",
        "  return (logits.squeeze())"
      ],
      "metadata": {
        "id": "wWeirVqrVx1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_label(model, X, tokenizer):\n",
        "  model.eval()\n",
        "  # Tokenize the input text\n",
        "  inputs = tokenizer.encode(\"$simple$ ; $expert$ = \" + X, return_tensors=\"pt\")\n",
        "\n",
        "  # Generate output from the model\n",
        "  outputs = model.generate(inputs.to(device), num_beams=4, early_stopping=True, max_new_tokens=200)\n",
        "\n",
        "  # Decode the output tokens to text\n",
        "  output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  return (output_text)"
      ],
      "metadata": {
        "id": "wsdyzWDVV0Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(student,\n",
        "          X,\n",
        "          y,\n",
        "          loss_fn,\n",
        "          optimizer):\n",
        "\n",
        "  student.train()\n",
        "  train_loss = 0\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    y_student = get_logits(student, X[i], tokenizer)\n",
        "\n",
        "    loss = loss_fn(y_student, y[i].requires_grad_())\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss = train_loss / len(X)\n",
        "  return(train_loss)"
      ],
      "metadata": {
        "id": "6JAvVoMGV1tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "UJevLhV9WYk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(student.parameters())"
      ],
      "metadata": {
        "id": "wOSvLX5BWYDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train (temporary)"
      ],
      "metadata": {
        "id": "g9YMsqqxWjLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_history = []\n",
        "for epoch in range(1000):\n",
        "  loss = train(student, X[:80], logits[:80], loss_fn, optimizer)\n",
        "  # loss_history.append(loss)\n",
        "  # torch.save({\n",
        "  #     \"epoch\": epoch,\n",
        "  #     \"model_state_dict\": student.state_dict(),\n",
        "  #     \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "  #     \"train_loss_history\": loss_history\n",
        "  # }, \"./student_actual.pth\")\n",
        "  if (epoch % 10 == 0):\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "xTo65IuoWlM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}